---
title: Workflows API reference
description: In this section we look at the public API related to workflows and how you can use it.
icon: network-wired
---

Here is an overview of the available API in the Tilebox Python client related to workflows. This page is intended as a
quick reference to look up the API. For more detailed information, please refer to the dedicated sections in the
Workflows documentation.

## Implementing a Task

<Row>
    <Col>
        A [task](/workflows/tasks) can be implemented by subclassing the `Task` class and overriding the `execute` method.

        ### Passed Parameters
        <Properties>
            <Property name="context" type="ExecutionContext">
                An object that provides access to the execution context of the task and allows you to interact with the
                Tilebox Workflows API.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Implementing a Task">
            ```python Python (Sync)
            from tilebox.workflows import Task, ExecutionContext

            class MyFirstTask(Task):
                def execute(self, context: ExecutionContext):
                    print(f"Hello World!")
            ```
            ```python Python (Async)
            from tilebox.workflows import Task, ExecutionContext

            class MyFirstTask(Task):
                def execute(self, context: ExecutionContext):
                    print(f"Hello World!")
            ```
        </CodeGroup>
    </Col>

</Row>

## Task Inputs

<Row>
    <Col>
        A task can optionally define [input parameters](/workflow/tasks#input-parameters). These parameters are defined as
        class attributes, similar to how you would define a dataclass.
    </Col>
    <Col sticky>
        <CodeGroup title="Task Inputs">
            ```python Python (Sync)
            from tilebox.workflows import Task, ExecutionContext

            class ParametrizableTask(Task):
                message: str
                number: int
                data: dict[str, str]

                def execute(self, context: ExecutionContext):
                    ...
            ```
            ```python Python (Async)
            from tilebox.workflows import Task, ExecutionContext

            class ParametrizableTask(Task):
                message: str
                number: int
                data: dict[str, str]

                def execute(self, context: ExecutionContext):
                    ...
            ```
        </CodeGroup>
    </Col>

</Row>

## Subtasks

<Row>
    <Col>
        In order to submit [subtasks](/workflows/tasks#subtasks-and-task-composition) from a task, you can use the
        `submit_subtask` method of the passed `ExecutionContext` object.

        Returns a `FutureTask` object that represents the subtask that was submitted. This object can be used to
        specify dependencies between tasks.

        ### Parameters
        <Properties>
            <Property name="task" type="Task">
                The task to be submitted as a subtask.
            </Property>
            <Property name="depends_on" type="list[FutureTask]">
                An optional list of other tasks previously submitted within the same context that this subtask depends on.
            </Property>
            <Property name="cluster" type="str">
                An optional [cluster slug](/workflows/clusters#managing-clusters) to run the subtask on. If not provided,
                the subtask will run on the same cluster as the parent task.
            </Property>
            <Property name="max_retries" type="int">
                Specify the maximum number of [retries](/workflows/tasks#retry-handling) for the subtask in case of failure. Defaults to 0.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Subtasks">
            ```python Python (Sync)
            # within the execute method of a Task:
            subtask = context.submit_subtask(MySubtask())
            dependent_subtask = context.submit_subtask(
                MyOtherSubtask(), depends_on=[subtask]
            )
            gpu_task = context.submit_subtask(
                MyGPUTask(),
                cluster="gpu-cluster-slug"
            )
            flaky_task = context.submit_subtask(
                MyFlakyTask(),
                max_retries=5
            )
            ```
            ```python Python (Async)
            # within the execute method of a Task:
            subtask = context.submit_subtask(MySubtask())
            dependent_subtask = context.submit_subtask(
                MyOtherSubtask(), depends_on=[subtask]
            )
            gpu_task = context.submit_subtask(
                MyGPUTask(),
                cluster="gpu-cluster-slug"
            )
            flaky_task = context.submit_subtask(
                MyFlakyTask(),
                max_retries=5
            )
            ```
        </CodeGroup>
    </Col>

</Row>

## Task Display Name

<Row>
  <Col>
    Within the `execute` method of a task, you can access and overwrite the `display` attribute of the `current_task`
    attribute of the passed `ExecutionContext` object. This allows you to modify the display name of the task in
    [visualizations](/workflows/jobs#visualization).
  </Col>
  <Col sticky>
    <CodeGroup title="Task Display Name">
      ```python Python (Sync) # within the execute method of a Task: context.current_task.display = "My Custom Task
      Name" ``` ```python Python (Async) # within the execute method of a Task: context.current_task.display = "My
      Custom Task Name" ```
    </CodeGroup>
  </Col>
</Row>

## Creating a Task Runner

<Row>
    <Col>
        From a [client instance](/workflows/creating) you can create a [TaskRunner](/workflows/task-runners),
        capable of executing tasks.

        ### Parameters
        <Properties>
            <Property name="cluster" type="str">
                The [cluster slug](/workflows/clusters#managing-clusters) of the cluster that this task runner will belong to.
            </Property>
            <Property name="tasks" type="list[type[Task]]">
                A list of task classes that this runner is capable of executing.
            </Property>
            <Property name="cache" type="JobCache">
                An optional [job cache](/workflows/caches) to use for caching intermediate task results and passing
                data between tasks.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Creating a Task Runner">
            ```python Python (Sync)
            from tilebox.workflows import Client
            from tilebox.workflows.cache import LocalFileSystemCache

            client = Client()
            runner = client.runner(
                "my-cluster-EdsdUozYprBJDL",
                [MyFirstTask, MySubtask],
                cache=LocalFileSystemCache("cache_directory"),  # optional
            )
            ```
            ```python Python (Async)
            from tilebox.workflows.aio import Client
            from tilebox.workflows.cache import LocalFileSystemCache

            client = Client()
            runner = await client.runner(
                "my-cluster-EdsdUozYprBJDL",
                [MyFirstTask, MySubtask],
                cache=LocalFileSystemCache("cache_directory"),  # optional
            )
            ```
        </CodeGroup>
    </Col>

</Row>

## Starting a Task Runner

<Row>
  <Col>
    Once you have created a [TaskRunner](/workflows/task-runners), you can start it by calling the `run_forever` method.
    This method will start the runner and keep it running until the process is terminated. If no tasks are available,
    the runner will idle and wait until work is available.
  </Col>
  <Col sticky>
    <CodeGroup title="Starting a Task Runner">

      ```python Python (Sync)
      runner.run_forever()
      ```

      ```python Python (Async)
      await runner.run_forever()
      ```

    </CodeGroup>

  </Col>
</Row>

## Submitting a Job

<Row>
    <Col>
        In order to actually execute a workflow, you need to submit a [job](/workflow/jobs) to the Tilebox API. This can be done by calling
        the `submit` method of a `JobClient` instance.

        ### Parameters
        <Properties>
            <Property name="job_name" type="str">
                A name for the job.
            </Property>
            <Property name="task" type="Task">
                A root task for the job. This task will be executed first and can submit subtasks to orchestrate a
                whole workflow.
            </Property>
            <Property name="cluster" type="str">
                The [cluster slug](/workflows/clusters#managing-clusters) of the cluster to submit the job to.
            </Property>
            <Property name="max_retries" type="int">
               Specify the maximum number of [retries](/workflows/tasks#retry-handling) for the subtask in case of failure. Defaults to 0.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Submitting a Job">
            ```python Python (Sync)
            from tilebox.workflows import Client

            client = Client()
            job_client = client.jobs()
            job = job_client.submit(
                "my-first-job",
                MyFirstTask(message="Hello, World!", number=42, data={"key": "value"}),
                "my-cluster-EdsdUozYprBJDL",
                max_retries=0,
            )
            ```
            ```python Python (Async)
            from tilebox.workflows.aio import Client

            client = Client()
            job_client = await client.jobs()
            job = await job_client.submit(
                "my-first-job",
                MyFirstTask(message="Hello, World!", number=42, data={"key": "value"}),
                "my-cluster-EdsdUozYprBJDL",
                max_retries=0,
            )
            ```
        </CodeGroup>
    </Col>

</Row>

## Retrying a Job

<Row>
    <Col>
        If a job fails, you can retry it by calling the `retry` method of the `JobClient` instance.

        ### Parameters
        <Properties>
            <Property name="job" type="Job">
                The job to retry.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Retrying a Job">
            ```python Python (Sync)
            job = job_client.submit(...)  # see above
            # job is now executing on some task runners, but fails
            # so let's retry it
            job_client.retry(job)
            ```
            ```python Python (Async)
            job = await job_client.submit(...)  # see above
            # job is now executing on some task runners, but fails
            # so let's retry it
            await job_client.retry(job)
            ```
        </CodeGroup>
    </Col>

</Row>

## Cancelling a Job

<Row>
    <Col>
        The execution of a job can be cancelled by calling the `cancel` method of the `JobClient` instance.

        If after cancelling a job you want to resume it, you can [retry](#retrying-a-job) it to undo the cancellation.

        ### Parameters
        <Properties>
            <Property name="job" type="Job">
                The job to cancel.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Cancelling a Job">
            ```python Python (Sync)
            job_client.cancel(job)
            ```
            ```python Python (Async)
            await job_client.cancel(job)
            ```
        </CodeGroup>
    </Col>

</Row>

## Visualizing a Job

<Row>
    <Col>
        If you want to [visualize a job](/workflows/jobs#visualization), you can call the `display` or the `visualize`
        method of the `JobClient` instance.

        `display` is designed to be used in an interactive environment such as a Jupyter notebook, and will display the
        visualization directly in the notebook.

        `visualize` is designed to be used in a non-interactive environment and will return a string - the job diagram
        as a SVG image.

        Both methods have the same parameters.

        ### Parameters
        <Properties>
            <Property name="job" type="Job">
                The job to visualize.
            </Property>
            <Property name="direction" type="str">
                An explicit direction for the diagram to flow towards. See the relevant section in the [D2 docs](https://d2lang.com/tour/layouts/#direction)
                for more detail. Valid values are `up`, `down`, `right`, `left`. Defaults to `down`.
            </Property>
            <Property name="layout" type="str">
                A layout engine to use for the diagram. See [D2 layout engines](https://d2lang.com/tour/layouts) for more information.
                Valid values are `dagre` and `elk`. Defaults to `dagre`.
            </Property>
            <Property name="sketchy" type="bool">
                Whether to use a sketchy, hand-drawn style for the diagram. Defaults to `True`.
            </Property>
        </Properties>
    </Col>
    <Col sticky>
        <CodeGroup title="Visualizing a Job">
            ```python Python (Sync)
            svg: str = job_client.visualize(job)

            # or if you are in a Jupyter notebook:
            job_client.display(job)
            ```
            ```python Python (Async)
            svg: str = await job_client.visualize(job)

            # or if you are in a Jupyter notebook:
            await job_client.display(job)
            ```
        </CodeGroup>
    </Col>

</Row>

## Cluster Management

<Row>
    <Col>
        You can use an instance of the `ClusterClient` to find, list, create and delete clusters.
    </Col>
    <Col sticky>
        <CodeGroup title="Cluster Management">
            ```python Python (Sync)
            from tilebox.workflows import Client

            client = Client()
            cluster_client = client.clusters()

            # Find, List, Create and Delete clusters
            cluster = cluster_client.find("my-cluster-EdsdUozYprBJDL")  # cluster-slug
            all_clusters = cluster_client.all()
            # will generate a new cluster slug from the provided name
            cluster = cluster_client.create("My Cluster")
            cluster_client.delete("my-cluster-EdsdUozYprBJDL")
            ```
            ```python Python (Async)
            from tilebox.workflows import Client

            client = Client()
            cluster_client = await client.clusters()

            # Find, List, Create and Delete clusters
            cluster = await cluster_client.find("my-cluster-EdsdUozYprBJDL")  # cluster-slug
            all_clusters = await cluster_client.all()
            # will generate a new cluster slug from the provided name
            cluster = await cluster_client.create("My Cluster")
            await cluster_client.delete("my-cluster-EdsdUozYprBJDL")
            ```
        </CodeGroup>
    </Col>

</Row>

## Cache access

<Row>
    <Col>
        You can use the `job_cache` attribute of the `ExecutionContext` object to access a shared cache for the job.
        The cache is a key value store, where the keys are strings and the values are bytes.
        This allows you to pass data between tasks. Make sure to specify dependencies between tasks to ensure that certain
        cache keys are only accessed after they have been written to.
    </Col>
    <Col sticky>
        <CodeGroup title="Cache access">
            ```python Python (Sync)
            class WriterTask(Task):
                def execute(self, context: ExecutionContext):
                    context.job_cache["some-key"] = b"my-value"

            class ReaderTask(Task):
                def execute(self, context: ExecutionContext):
                    data = context.job_cache["some-key"]
            ```
            ```python Python (Async)
            class WriterTask(Task):
                def execute(self, context: ExecutionContext):
                    context.job_cache["some-key"] = b"my-value"

            class ReaderTask(Task):
                def execute(self, context: ExecutionContext):
                    data = context.job_cache["some-key"]
            ```
        </CodeGroup>
    </Col>

</Row>

## Hierarchical Caches

<Row>
    <Col>
        In addition to a simple key value store, it is also possible to hierarchically nest caches into [groups](/workflows/caches#groups-and-hierarchical-keys).
        Groups are denoted by a forward slash `/` in the key. Cache hierarchies therefore behave in a similar way to file systems.
    </Col>
    <Col sticky>
        <CodeGroup title="Hierarchical Caches">
            ```python Python (Sync)
            class WriterTask(Task):
                def execute(self, context: ExecutionContext):
                    context.job_cache["some-group/value_a"] = b"some"
                    context.job_cache["some-group/value_b"] = b"cached"

                    # same as above, but explicitly using the group method
                    group = context.job_cache.group("some-group")
                    group["value_c"] = b"data"

            class ReaderTask(Task):
                def execute(self, context: ExecutionContext):
                    group = context.job_cache.group("some-group")
                    # we can iterate over all keys in the group
                    for key in group:
                        # prints "some", "cached", "data"
                        print(group[key])
            ```
        </CodeGroup>
    </Col>

</Row>
