---
title: Async support
description: Tilebox offers a standard synchronous API by default, but also give you to option of an async client if you need it.
icon: rotate
---

## Why async?

Often case when interacting with external datasets, such as [Tilebox datasets](/datasets/timeseries) loading data
can take a little while. One way to speed up this process is to run those requests in parallel. This can be achieved
by multi-threading or multi-processing, but this is not always easiest method of achieving this. An alternative is
to perform data loading tasks in an async manner, leveraging co-routines and `asyncio` to achieve this.

## Switching to an async datasets client

Typically all you need to do is swap out your import statement of the `Client` and you're good to go. Check out
the example below to see how that is done works.

<CodeGroup>
```python Python (Sync)
from tilebox.datasets import Client

# this client is sync
client = Client()
```
```python Python (Async)
from tilebox.datasets.aio import Client

# this client is async
client = Client()
```

</CodeGroup>

Once you have switched to the async client, you can use the `async` and `await` keywords to make your code async.
Check out the examples below to see how that works for a few examples.

<CodeGroup>

```python Python (Sync)
# Listing datasets
datasets = client.datasets()

# Listing collections
dataset = datasets.open_data.copernicus.sentinel1_sar
collections = dataset.collections()

# Collection information
collection = collections["S1A_IW_RAW__0S"]
info = collection.info()
print(f"Data for My-collection is available for {info.availability}")

# Loading data
data = collection.load(("2022-05-01", "2022-06-01"), show_progress=True)

# Finding a specific datapoint
datapoint_uuid = "01910b3c-8552-7671-3345-b902cc0813f3"
datapoint = collection.find(datapoint_uuid)
```

```python Python (Async)
# Listing datasets
datasets = await client.datasets()

# Listing collections
dataset = datasets.open_data.copernicus.sentinel1_sar
collections = await dataset.collections()

# Collection information
collection = collections["S1A_IW_RAW__0S"]
info = await collection.info()
print(f"Data for My-collection is available for {info.availability}")

# Loading data
data = await collection.load(("2022-05-01", "2022-06-01"), show_progress=True)

# Finding a specific datapoint
datapoint_uuid = "01910b3c-8552-7671-3345-b902cc0813f3"
datapoint = await collection.find(datapoint_uuid)
```

</CodeGroup>

<Note>
  Jupyter notebooks or similar interactive environments also support asynchronous code execution. You can even use
  `await some_async_call()` as the output of a code cell.
</Note>

## Benefits

The main benefit of using an async client is that you can run requests concurrently, which improve performance.
This is especially useful when you are loading data from different collections.
Check out the example below to see how that works.

## Example: Fetching data concurrently

The following example fetches data from different collections.
In the synchronous example, it fetches the data sequentially, whereas in the async example it fetches the data concurrently.
This means that the async approach is faster for such use cases.

<CodeGroup>

```python Python (Sync)
# example: fetching data sequentially

import time
from tilebox.datasets import Client
from tilebox.datasets.timeseries import RemoteTimeseriesDatasetCollection  # for type hinting

client = Client()
datasets = client.datasets()
collections = datasets.open_data.copernicus.landsat8_oli_tirs.collections()

def stats_for_2020(collection: RemoteTimeseriesDatasetCollection) -> None:
    """Fetch data for 2020 and print the number of data points that were loaded."""
    data = collection.load(("2020-01-01", "2021-01-01"), show_progress=True)
    n = data.sizes['time'] if 'time' in data else 0
    print(f"There are {n} datapoints in {collection.name} for 2020.")

start = time.time()

# for each collection
for name in collections:
    # fetch the data, print the number of datapoints and then continue to the next collection
    stats_for_2020(collections[name])

end = time.time()
print(f"Fetching data took {end - start:.2f} seconds")
```

```python Python (Async)
# example: fetching data concurrently

import asyncio
import time
from tilebox.datasets.aio import Client
from tilebox.datasets.timeseries import RemoteTimeseriesDatasetCollection  # for type hinting

client = Client()
datasets = await client.datasets()
collections = await datasets.open_data.copernicus.landsat8_oli_tirs.collections()

async def stats_for_2020(collection: RemoteTimeseriesDatasetCollection) -> None:
    """Fetch data for 2020 and print the number of data points that were loaded."""
    data = await collection.load(("2020-01-01", "2021-01-01"), show_progress=True)
    n = data.sizes['time'] if 'time' in data else 0
    print(f"There are {n} datapoints in {collection.name} for 2020.")

start = time.time()

# initiate all requests concurrently
requests = [stats_for_2020(collections[name]) for name in collections]
# and then wait for all to finish in parallel before continuing
await asyncio.gather(*requests)

end = time.time()
print(f"Fetching data took {end - start:.2f} seconds")
```

</CodeGroup>

The output is shown below. As you can see, the async approach is 5 seconds faster. If you have `show_progress` enabled,
the progress bars are updated concurrently. In this example the second collection contains less data than the first one,
so it finishes first.

<CodeGroup>

```plaintext Python (Sync)
There are 19624 datapoints in L1GT for 2020.
There are 1281 datapoints in L1T for 2020.
There are 65313 datapoints in L1TP for 2020.
There are 25375 datapoints in L2SP for 2020.
Fetching data took 10.92 seconds
```

```plaintext Python (Async)
There are 1281 datapoints in L1T for 2020.
There are 19624 datapoints in L1GT for 2020.
There are 25375 datapoints in L2SP for 2020.
There are 65313 datapoints in L1TP for 2020.
Fetching data took 7.45 seconds
```

</CodeGroup>

## Async workflows

The Tilebox workflows Python client doesn't offer an async client. That's because workflows are already designed to be
executed in a distributed and concurrent fashion - outside of the context of a single async event loop.
But within a single task execution, you may still want to use `async` code, to leverage the benefits of async execution, such
as loading data in parallel. Achieving this is straightforward, by wrapping your async code in `asyncio.run`.

Below is an example of how you can leverage async code within a workflow task.

<CodeGroup>
```python Python (Async)
import asyncio
import xarray as xr

from tilebox.datasets.aio import Client as DatasetsClient
from tilebox.datasets.data import TimeIntervalLike
from tilebox.workflows import Task, ExecutionContext

class FetchData(Task):
    def execute(self, ctx: ExecutionContext) -> None:
        # the task execute itself is a synchronous function
        # but we can leverage async code within the task, by using asyncio.run

        # this will fetch the three months of data in parallel
        data_jan, data_feb, data_mar = asyncio.run(load_first_three_months())
        
async def load_data(interval: TimeIntervalLike):
    datasets = await DatasetsClient().datasets()
    collections = await datasets.open_data.copernicus.landsat8_oli_tirs.collections()
    return await collections["L1T"].load(interval)

async def load_first_three_months() -> tuple[xr.Dataset, xr.Dataset, xr.Dataset]:
    jan = load_data(("2020-01-01", "2020-02-01"))
    feb = load_data(("2020-02-01", "2020-03-01"))
    mar = load_data(("2020-03-01", "2020-04-01"))
    jan, feb, mar = await asyncio.gather(jan, feb, mar)
    return jan, feb, mar
```
</CodeGroup>

<Tip>
    If you encounter an error like `RuntimeError: asyncio.run() cannot be called from a running event loop`, it means
    you are trying to start another asyncio event loop (with `asyncio.run`) from within an already running event loop.
    One situation where this can easily occur is if you are using `asyncio.run` in a Jupyter notebook, since Jupyter
    automatically starts an event loop for you. One way to work around this is to use [nest-asyncio](https://pypi.org/project/nest-asyncio/).
</Tip>
