---
title: Logging
description: Set up distributed logging using the OpenTelemetry logging protocol
icon: rectangle-terminal
---

## Overview

Tilebox workflows are designed for distributed execution, making it essential to set up logging to a centralized system. Tilebox supports OpenTelemetry logging, which simplifies sending log messages from your tasks to a chosen backend. Collecting and visualizing logs from a distributed cluster of task runners in a tool like [Axiom](https://axiom.co/) can look like this:

<Frame>
  <img src="/assets/workflows/observability/logs-light.png" alt="Tilebox Workflows logging in Axiom" className="dark:hidden" />
  <img src="/assets/workflows/observability/logs-dark.png" alt="Tilebox Workflows logging in Axiom" className="hidden dark:block" />
</Frame>

## Configure logging

The Tilebox workflow SDKs include support for exporting OpenTelemetry logs. To enable logging, call the appropriate configuration functions during the startup of your[task runner](/workflows/concepts/task-runners). Then, use the provided `logger` to send log messages from your tasks.

<Tabs>
    <Tab title="Axiom">
    To configure logging with Axiom, you first need to create a [Axiom Dataset](https://axiom.co/docs/reference/datasets) to export your workflow logs to. You will also need an [Axiom API key](https://axiom.co/docs/reference/tokens) with the necessary write permissions for your Axiom dataset.
    
    ```python Python
    from tilebox.workflows import Client, Task, ExecutionContext
    from tilebox.workflows.observability.logging import configure_otel_logging_axiom

    # your own workflow:
    from my_workflow import MyTask

    def main():
        configure_otel_logging_axiom(
            # specify an Axiom dataset to export logs to
            dataset="my-axiom-logs-dataset",
            # along with an Axiom API key with ingest permissions for that dataset
            api_key="my-axiom-api-key",
        )

        # the task runner will export logs from 
        # the executed tasks to the specified dataset
        client = Client()
        runner = client.runner("dev-cluster", tasks=[MyTask])
        runner.run_forever()
    
    if __name__ == "__main__":
        main()
    ```

    <Tip>
        Setting the environment variables `AXIOM_API_KEY` and `AXIOM_LOGS_DATASET` allows you to omit these arguments in the `configure_otel_logging_axiom` function.
    </Tip>
    
    </Tab>
    <Tab title="OpenTelemetry-compatible backend">
    If you are using another OpenTelemetry-compatible backend besides Axiom, such as OpenTelemetry Collector or Jaeger, you can configure logging by specifying the URL endpoint to export log messages to.

    ```python Python
    from tilebox.workflows import Client
    from tilebox.workflows.observability.logging import configure_otel_logging

    # your own workflow:
    from my_workflow import MyTask

    def main():
        configure_otel_logging(
            # specify an endpoint to export logs to, such as a
            # locally running instance of OpenTelemetry Collector
            endpoint="http://localhost:4318/v1/logs",
            # optional headers for each request
            headers={"Authorization": "Bearer some-api-key"},
        )

        # the task runner will export logs from 
        # the executed tasks to the specified endpoint
        client = Client()
        runner = client.runner("dev-cluster", tasks=[MyTask])
        runner.run_forever()
    
    if __name__ == "__main__":
        main()
    ```

    <Tip>
        If you set the environment variable `OTEL_LOGS_ENDPOINT`, you can omit that argument in the `configure_otel_logging` function.
    </Tip>
    </Tab>
    <Tab title="Console">
        To log messages to the standard console output, use the `configure_console_logging` function.

        ```python Python
        from tilebox.workflows import Client
        from tilebox.workflows.observability.logging import configure_console_logging

        # your own workflow:
        from my_workflow import MyTask

        def main():
            configure_console_logging()

            # the task runner will print log messages from
            # the executed tasks to the console
            client = Client()
            runner = client.runner("dev-cluster", tasks=[MyTask])
            runner.run_forever()
        
        if __name__ == "__main__":
            main()
        ```

        <Warning>
            The console logging backend is not recommended for production use. Log messages will be emitted to the standard output of each task runner rather than a centralized logging system. It is intended for local development and testing of workflows.
        </Warning>
    </Tab>

</Tabs>

## Emitting log messages

Use the logger provided by the Tilebox SDK to emit log messages from your tasks. You can then use it to send log messages to the [configured logging backend](#configure-logging).
Log messages emitted within a task's `execute` method are also automatically recorded as span events for the current [job trace](/workflows/observability/tracing).

```python Python
import logging
from tilebox.workflows import Task, ExecutionContext
from tilebox.workflows.observability.logging import get_logger

logger = get_logger()

class MyTask(Task):
    def execute(self, context: ExecutionContext) -> None:
        # emit a log message to the configured OpenTelemetry backend
        logger.info("Hello world from configured logger!")
```

## Logging task runner internals

Tilebox task runners also internally use a logger. By default, it's set to the WARNING level, but you can change it by explicitly configuring a logger for the workflows client when constructing the task runner.

```python Python
from tilebox.workflows import Client

from tilebox.workflows.observability.logging import configure_otel_logging_axiom
from tilebox.workflows.observability.logging import get_logger

# configure Axiom or another logging backend
configure_otel_logging_axiom(
    dataset="my-axiom-logs-dataset",
    api_key="my-axiom-api-key",
)

# configure a logger for the Tilebox client at the INFO level
client = Client()
client.configure_logger(get_logger(level=logging.INFO))

# now the task runner inherits this logger and uses
# it to emit its own internal log messages as well
runner = client.runner("dev-cluster", tasks=[MyTask])
runner.run_forever()
```
